% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tidyDiscreteContinuousMI.R
\name{calculateDiscreteContinuousMI_KWindow}
\alias{calculateDiscreteContinuousMI_KWindow}
\title{calculate mutual information between a categorical value (X) and a continuous value (Y) using a sliding window and local entropy measure}
\usage{
calculateDiscreteContinuousMI_KWindow(df, groupXVar, valueYVar, k_05 = 2)
}
\arguments{
\item{df}{- may be grouped, in which case the value is interpreted as different types of continuous variable}

\item{groupXVar}{- the column of the categorical value (X)}

\item{valueYVar}{- the column of the continuous value (Y)}

\item{k_05}{- half the sliding window width - this should be a small number like 1,2,3.}
}
\value{
a dataframe containing the disctinct values of the groups of df, and for each group a mutual information column (I). If df was not grouped this will be a single entry
}
\description{
This is based on the technique described here:
B. C. Ross, “Mutual information between discrete and continuous data sets,” PLoS One, vol. 9, no. 2, p. e87357, Feb. 2014 [Online]. Available: http://dx.doi.org/10.1371/journal.pone.0087357
but with the important simplification of using the sliding window K elements wide rather than the k nearest neighbours. This is empirically shown to have little difference on larger datasets
and makes this algorithm simple to implement in dbplyr tables.
}
