---
title: "test-estimate-accuracy"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(infotheo)
library(tidyverse)
library(ggplot2)
library(devtools)
library(standardPrintOutput)
#library(tidyinfostats)
devtools::load_all("..")
set.seed(101)
theme_set(standardPrintOutput::defaultFigureLayout())
```



## Define test distributions

### gaussians
gaussian test params
y0 = [ .4 .5 .8 ];          % the center of the gaussian
sigma_y = [ .2 .3 .25 ];    % the gaussian decay constant
p{2} = [ .2 1 0.5 ];        % the (normalized) amplitude p(x)

```{r}
gaussians = ConditionalDistribution$new()
gaussians$withDistribution(0.2,NormalDistribution$new(0.4,0.2))
gaussians$withDistribution(1,NormalDistribution$new(0.5,0.3))
gaussians$withDistribution(0.5,NormalDistribution$new(0.8,0.25))
```

### Uniform distributions
square wave test params

a = [ 0 .1 .2 ];            % the left side of each square wave
b_a = [ 1 1.1 1.1 ];        % the length in y of each square wave
p{1} = [ .2 1 0.5 ];        % the (normalized) amplitude p(x)

```{r}
squareWaves = ConditionalDistribution$new()
squareWaves$withDistribution(0.2,UniformDistribution$new(min=0,max=1))
squareWaves$withDistribution(1,UniformDistribution$new(min=0.1,max=1.2))
squareWaves$withDistribution(0.5,UniformDistribution$new(min=0.2,max=1.3))
```

### Log normals

```{r}
lognorm = ConditionalDistribution$new()
lognorm$withDistribution(0.5,LogNormalDistribution$new(mode=0.5,sd=0.25))
lognorm$withDistribution(1,LogNormalDistribution$new(mode=1.5,sd=1))
lognorm$withDistribution(0.3,LogNormalDistribution$new(mode=2.5,sd=0.5))
```

### plot our distributions

```{r}
gaussians$plot(-1,2)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/gaussiansDist")
```

```{r}
squareWaves$plot(-0.5,1.5)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/squareDist")
```

```{r}
lognorm$plot(0,5)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/lognormDist")
```


## Experiment 1

B. C. Ross, “Mutual information between discrete and continuous data sets,” PLoS One, vol. 9, no. 2, p. e87357, Feb. 2014 [Online]. Available: http://dx.doi.org/10.1371/journal.pone.0087357

The first experiment replicates Ross's findings around discretising data & KNN method for estimating MI but using 2 new algorithms and only the smaller sample size

```{r echo=FALSE}
devtools::load_all("..")
experiment1 = function(distribution, sampleSize, reps) {
  
  kout = NULL
  thMi = distribution$theoreticalMI()
  thMu = distribution$theoreticalMean()
  thSd = sqrt(distribution$theoreticalVariance())
  
  for (i in c(1:reps)) {
	  # i = 1
	  df = distribution$sample(sampleSize)
	  estMean = mean(df$x)
  	estSd = sd(df$x)
  	
  	# SGolay method
	  k = c(5,7,10,15,20,30,40)
	  kresult = sapply(k, function(k2) (calculateDiscreteContinuousMI(df, y, x, method = "SGolay", k_05=k2) %>% pull(I)))
  	kout = kout %>% bind_rows(tibble(
  			method = rep("SGolay",length(k)),
  			param = rep("filter width",length(k)),
  			test = rep(i,length(k)),
  			value = k,
  			estimated.MI = kresult,
  			estimated.Mean = rep(estMean,length(k)),
  			estimated.Sd = rep(estSd,length(k))
  	))
	
		# KWindow method
  	k = c(2:10)
		wresult = sapply(k, function(k2) (calculateDiscreteContinuousMI(df, y, x, method = "KWindow", k_05=k2) %>% pull(I)))
	  kout = kout %>% bind_rows(tibble(
  			method = rep("KWindow",length(k)),
  			param = rep("window width",length(k)),
  			test = rep(i,length(k)),
  			value = k,
  			estimated.MI = wresult,
  			estimated.Mean = rep(estMean,length(k)),
  			estimated.Sd = rep(estSd,length(k))
  	))
	  
	  # KNN method
  	k = c(2:10)
		w2result = sapply(k, function(k2) (calculateDiscreteContinuousMI(df, y, x, method = "KNN", k_05=k2) %>% pull(I)))
	  kout = kout %>% bind_rows(tibble(
  			method = rep("KNN",length(k)),
  			param = rep("knn distance",length(k)),
  			test = rep(i,length(k)),
  			value = k,
  			estimated.MI = wresult,
  			estimated.Mean = rep(estMean,length(k)),
  			estimated.Sd = rep(estSd,length(k))
  	))
	  
	  
	  # Discretise method
	  binPow = seq(0.1,0.9,0.1)
	  k = floor(sampleSize^binPow)
	  nresult = sapply(k, function(k2) (calculateDiscreteContinuousMI(df, y, x, method = "Discrete", bins=k2) %>% pull(I)))
	  kout = kout %>% bind_rows(tibble(
  			method = rep("Discrete",length(k)),
  			param = rep("number bins",length(k)),
  			test = rep(i,length(k)),
  			value = sampleSize/k,
  			estimated.MI = nresult,
  			estimated.Mean = rep(estMean,length(k)),
  			estimated.Sd = rep(estSd,length(k))
  	))
	  
  }
  
  kout = kout %>% mutate(
    theoretical.MI = thMi,
  	theoretical.Mean = thMu,
  	theoretical.Sd = thSd
  )
  
  
  
  return(kout)
}


# todo summarise experimental data
plotExperiment1 = function(df) {
  exp1aDataGrouped = df %>% group_by(method,param,value) %>% summarise( #,estimatedMean,estimatedSd,theoreticalMI,theoreticalMean,theoreticalSd) %>% summarise(
    estMIMean = mean(estimated.MI),
    estMIsd = sd(estimated.MI)
  )

  # p3 = 
  return(
    ggplot(exp1aDataGrouped, aes(x=value))+
  		geom_ribbon(aes(ymin=estMIMean-1.96*estMIsd,ymax=estMIMean+1.96*estMIsd), fill = "grey75")+
  		geom_line(aes(y=estMIMean))+
  		#coord_cartesian(ylim = c(0,1))+
      expand_limits(y=0)+
    	geom_hline(yintercept=min(df$theoretical.MI), colour="blue")+
      facet_wrap(vars(method),scales = "free_x")
  )
}

```

### Experiment 1: gaussians

Using a sample size of 400 and 100 repetitions of the test for bootstrapping

```{r}
# debug(calculateDiscreteContinuousMI_SGolay)
exp1aData = experiment1(distribution=gaussians, sampleSize=400, reps=100)

plotExperiment1(exp1aData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/gaussiansEstimated400")
```

Using a sample size of 10000 and 100 repetitions of the test for bootstrapping

```{r}
exp1bData = experiment1(distribution=gaussians, sampleSize=10000, reps=100)
plotExperiment1(exp1bData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/gaussiansEstimated10K")
```

### Experiment 1: uniform

Using a sample size of 400 and 100 repetitions of the test for bootstrapping

```{r}
exp1cData = experiment1(distribution=squareWaves, sampleSize=400, reps=100)
plotExperiment1(exp1cData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/squareEstimated400")
```

Using a sample size of 10000 and 100 repetitions of the test for bootstrapping

```{r}
exp1dData = experiment1(distribution=squareWaves, sampleSize=10000, reps=100)
plotExperiment1(exp1dData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/squareEstimated10K")
```

### Experiment 1: log normal

Using a sample size of 400 and 100 repetitions of the test for bootstrapping

```{r}
exp1eData = experiment1(distribution=lognorm, sampleSize=400, reps=100)
plotExperiment1(exp1eData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/lognormEstimated400")
```

Using a sample size of 10000 and 100 repetitions of the test for bootstrapping

```{r}
exp1fData = experiment1(distribution=lognorm, sampleSize=10000, reps=100)
plotExperiment1(exp1fData)
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/lognormEstimated10K")
```

## Experiment 2

Objectives:
* Assess bias in KWindow estimate
** Random distributions
** Plot estimated versus theoretical MI
** Plot estimated versus theoretical Mean & Variance
** Corrected versus uncorrected?
*** Not done: solve estimated versus theoretical for parameters a&b for random distributions & samples


```{r echo=FALSE}

summariseError2 = function(df) {
  return(
    df %>% filter(!is.na(relativeError)) %>% group_by(sample,distributions,param) %>% summarise(
      theoretical = mean(theoretical, na.rm=TRUE),
      rmse = sqrt(mean(absoluteError^2, na.rm=TRUE)),
      mae = mean(absoluteError, na.rm=TRUE),
      vae = var(absoluteError, na.rm=TRUE),
      nmae = mean(relativeError, na.rm=TRUE),
      nvae = var(relativeError, na.rm=TRUE),
      median_ae = quantile(absoluteError, probs=c(0.5), names=FALSE, na.rm=TRUE),
      upper_iqr_ae = quantile(absoluteError, probs=c(0.75), names=FALSE, na.rm=TRUE),
      lower_iqr_ae = quantile(absoluteError, probs=c(0.25), names=FALSE, na.rm=TRUE)
    )
  )
}

experiment2 = function(reps,meth = c("KNN","KWindow","Discrete","SGolay")) {
  
  result = NULL
  
  for (i in c(1:reps)) {
    
    ndist = sample(2:4,1)
    distribution = ConditionalDistribution$new()$withRandomDistributions(ndist)
    thMi = tryCatch(distribution$theoreticalMI(), error = function(e) {NA})
    thMu = tryCatch(distribution$theoreticalMean(), error = function(e) {NA})
    thSd = tryCatch(sqrt(distribution$theoreticalVariance()), error = function(e) {NA})
    
    df = distribution$sample(1000)
    
    estMi = sapply(aAdj, function(a) calculateDiscreteContinuousMI(df, y, x, method = meth) %>% pull(I))
    estMean = mean(df$x)
    estSd = sd(df$x)
    
    result = result %>% bind_rows(
      tibble(
        sample = rep(i,length(meth)+2),
        distributions = rep(ndist,length(meth)+2),
        param = c(meth,"Mean","Std deviation"),
        theoretical = c(rep(thMi,length(meth)),thMu,thSd),
        estimated = c(estMi,estMean,estSd),
        absoluteError = estimated-theoretical,
        relativeError = ifelse(theoretical==0,NA,absoluteError/theoretical)
      )
    )
    
  }
  
  return(result)
}


# todo summarise experimental data
# TODO: plot relative error vs. theoretical MI
plotExperiment2 = function(df) {
  # p3 = 
  return(
    ggplot(df %>% filter(adjustmentFactor==1) %>% mutate(components=as.factor(distributions)), aes(x=theoretical,y=estimated,colour=components))+
  		geom_point()+
  		geom_abline(slope=1,intercept=0,colour="grey75")+
  		#coord_cartesian(ylim = c(0,1))+
    	facet_wrap(vars(param),scales = "free")
  )
}

```

### Experiment 2 part one - Error plots

```{r}
exp2adata = experiment2(1000)
plotExperiment2(exp2adata)
standardPrintOutput::saveHalfPageFigure(filename="~/Dropbox/featureSelection/mutinfo/error")

```

### Experiment 2 - part 2 

```{r}
df = exp2adata %>% mutate(components=as.factor(distributions))

tmp1 = df %>% filter(!is.na(error)) %>% group_by(`Estimate`=param) %>% group_modify(function(d,...) {
    tryCatch({
      tResult = t.test(d$error, paired=FALSE)
      tibble(
        `Error size` = twoDp(tResult$estimate),
        `Confidence interval` = paste0(twoDp(tResult$conf.int),collapse=", "),
        `P Value` = twoDp(tResult$p.value)
      )},
      error = function(e) {
        tibble(
        `Error size` = as.character(mean(d$error)),
        `Confidence interval` = paste0(mean(d$error),", ",mean(d$error)),
        `P Value` = "0"
        )
      }
    )
}) %>% group_by(Estimate) %>% standardPrintOutput::mergeCells() 

tmp1
tmp1 %>% standardPrintOutput::saveTable(filename = "~/Dropbox/featureSelection/mutinfo/adjustedError")
```

### Experiment 2 part 2

Perform t-test on 

```{r}
tmp2 = df %>% group_by(param) %>% group_modify(function(d,...) {
    tResult = t.test(d$theoretical, d$estimated, paired=TRUE)
    tibble(
      effectSize = twoDp(tResult$estimate),
      confidenceInt = paste0(twoDp(tResult$conf.int),collapse=", "),
      pValue = twoDp(tResult$p.value)
    )
}) %>% rename(`Estimate`=param, Difference = effectSize, `Confidence interval`=confidenceInt, `P value` = pValue ) %>% group_by(Estimate) %>% standardPrintOutput::mergeCells() 
tmp2
tmp2 %>% standardPrintOutput::saveTable(filename = "~/Dropbox/featureSelection/mutinfo/adjustedError2")
# ggplot(df, aes)
```

# Experiment 3

Objectives:
* Look at sample size versus accuracy
** MI, Mean and SD with increasing sample size
** regression to predict SD of MI from est mean versus theoretical mean  & est versus theoretical SD

```{r echo=FALSE}
devtools::load_all("..")
experiment3 = function(distribution, reps) {
  
  result = NULL
  
  thMi = tryCatch(distribution$theoreticalMI(), error = function(e) {NA})
  thMu = tryCatch(distribution$theoreticalMean(), error = function(e) {NA})
  thSd = tryCatch(sqrt(distribution$theoreticalVariance()), error = function(e) {NA})
  
  j=0
  for (samples in c(8,16,32,64,128,256,512,1024,2048,4096,8192,16384)) {
  
    for (i in c(1:reps)) {
      
      j=j+1
      
      df = distribution$sample(samples)
      minGroupSize = min(df %>% group_by(y) %>% count() %>% pull(n))
      estMi = calculateDiscreteContinuousMI(df, y, x, method = "KWindow") %>% pull(I)
      estMi2 = calculateDiscreteContinuousMI(df, y, x, method = "SGolay") %>% pull(I)
      estMi3 = calculateDiscreteContinuousMI(df, y, x, method = "Discrete") %>% pull(I)
      estMean = mean(df$x)
      estSd = sd(df$x)
    
      result = result %>% bind_rows(
        tibble(
          id = rep(j,5),
          minGroupSize = rep(minGroupSize,5),
          sample = rep(samples,5),
          param = c("MI KWindow","MI SGolay","MI Discrete","Mean","Std deviation"),
          theoretical = c(thMi,thMi,thMi,thMu,thSd),
          estimated = c(estMi,estMi2,estMi3,estMean,estSd)
        )
      )
    }
  }
  
  return(result)
}

# setup error

quantifyError = function(df) {
  return(
    df %>% mutate(
      absoluteError = estimated-theoretical,
      relativeError = ifelse(theoretical==0,NA,absoluteError/theoretical)
    ) %>% filter(!is.na(relativeError)) %>% group_by(sample,param) %>% summarise(
      minGroupSize =mean(minGroupSize),
      theoretical = mean(theoretical, na.rm=TRUE),
      rmse = sqrt(mean(absoluteError^2, na.rm=TRUE)),
      mae = mean(absoluteError, na.rm=TRUE),
      vae = var(absoluteError, na.rm=TRUE),
      nmae = mean(relativeError, na.rm=TRUE),
      nvae = var(relativeError, na.rm=TRUE),
      median_ae = quantile(absoluteError, probs=c(0.5), names=FALSE, na.rm=TRUE),
      upper_iqr_ae = quantile(absoluteError, probs=c(0.75), names=FALSE, na.rm=TRUE),
      lower_iqr_ae = quantile(absoluteError, probs=c(0.25), names=FALSE, na.rm=TRUE)
    )
  )
}

# todo summarise experimental data
plotExperiment3 = function(df, components) {
  summary = df %>% group_by(sample,param) %>% quantifyError()
  return(ggplot(summary %>% filter(param %in% components),aes(x=sample))+
  		geom_line(aes(y=nmae),colour="blue")+
  		geom_ribbon(aes(ymin=nmae-1.96*nvae,ymax=nmae+1.96*nvae),fill="blue",alpha=0.1)+
  		#geom_line(aes(y=estimatedMedian),colour="grey75")+
  		#geom_ribbon(aes(ymin=estimatedLower,ymax=estimatedUpper),fill="grey75",alpha=0.1)+
  		coord_cartesian(ylim = c(-0.5,0.5))+
      geom_hline(yintercept=0, colour="red")+
    	facet_wrap(vars(param))+scale_x_log10())
}



```
```{r}
exp3aData = experiment3(lognorm,100)
exp3bData = experiment3(gaussians,100)
exp3cData = experiment3(squareWaves,100)
```


```{r}
# devtools::load_all("..")

plotExperiment3(exp3aData,c("Mean","Std deviation"))
plotExperiment3(exp3aData,c("MI KWindow","MI SGolay","MI Discrete"))
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/bootstrappingLogNorm")
```

```{r}
#devtools::load_all("..")

plotExperiment3(exp3bData,c("Mean","Std deviation"))
plotExperiment3(exp3bData,c("MI KWindow","MI SGolay","MI Discrete"))
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/bootstrappingGaussians")
```

```{r}
# devtools::load_all("..")

plotExperiment3(exp3cData,c("Mean","Std deviation"))
plotExperiment3(exp3cData,c("MI KWindow","MI SGolay","MI Discrete"))
standardPrintOutput::saveThirdPageFigure(filename="~/Dropbox/featureSelection/mutinfo/bootstrappingUniform")
```